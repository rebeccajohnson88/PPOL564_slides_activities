{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reshaping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulated data from review session\n",
    "np.random.seed(1129)\n",
    "shop_names = ['Compass', 'Starbucks', 'Baked and Wired', 'Peets', \n",
    "              'Blue Bottle', 'Saxbys']\n",
    "coffee_df = pd.concat([pd.DataFrame({'shop_name': shop_names,\n",
    "                         'opening_time': np.random.choice([\"8:00 AM\", \"9:00 AM\", \"10:00 AM\"],\n",
    "                                                       len(shop_names),\n",
    "                                                       replace = True),\n",
    "                         'closing_time': np.random.choice([\"5:00 PM\", \"6:00 PM\", \n",
    "                                                          \"7:00 PM\"],\n",
    "                                                         len(shop_names),\n",
    "                                                          replace = True),\n",
    "                         'hourly_wage': np.random.uniform(14, 20,\n",
    "                                                          len(shop_names)),\n",
    "                        'year': 2019}),\n",
    "                      pd.DataFrame({'shop_name': shop_names,\n",
    "                         'opening_time': np.random.choice([\"8:00 AM\", \"9:00 AM\", \"10:00 AM\"],\n",
    "                                                       len(shop_names),\n",
    "                                                       replace = True),\n",
    "                         'closing_time': np.random.choice([\"3:00 PM\", \"4:00 PM\",\n",
    "                                                           \"6:00 PM\", \n",
    "                                                          \"7:00 PM\"],\n",
    "                                                         len(shop_names),\n",
    "                                                          replace = True),\n",
    "                         'hourly_wage': np.random.uniform(14, 20,\n",
    "                                                          len(shop_names)),\n",
    "                        'year': 2021})]).sort_values(by = 'shop_name')\n",
    "                      \n",
    "\n",
    "coffee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create a wide-format dataframe where we have the hourly wage for each year as a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create a long-format dataframe where we have the hourly wage for each year as a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Practice for you\n",
    "\n",
    "Using the original `coffee_df`:\n",
    "\n",
    "- Reshape to wide format for opening_time and closing_time (you can remove hourly_wage) from the data\n",
    "- Use list comprehension to subset the dataframe to the shop_name and 2019 times only (so shop_name, opening_time 2019 and closing time 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Read in the two datasets \n",
    "\n",
    "- San Diego data: `naics_code` and `account_key`\n",
    "- NAICS details data: `naics` \n",
    "\n",
    "Run code below; if pulling from github, pathname should be fine; if working elsewhere may need to edit path name at read in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_df = pd.read_csv(\"../../public_data/sd_df.csv\")\n",
    "naics_df = pd.read_csv(\"../../public_data/naics_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_key</th>\n",
       "      <th>dba_name</th>\n",
       "      <th>council_district</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>naics_description</th>\n",
       "      <th>naics_nchar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974000448</td>\n",
       "      <td>ERNST &amp; YOUNG LLP</td>\n",
       "      <td>cd_1</td>\n",
       "      <td>541211</td>\n",
       "      <td>OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974011093</td>\n",
       "      <td>HECHT SOLBERG ROBINSON GOLDBERG &amp; BAGLEY LLP</td>\n",
       "      <td>cd_3</td>\n",
       "      <td>5411</td>\n",
       "      <td>LEGAL SERVICES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1978039819</td>\n",
       "      <td>RSM US LLP</td>\n",
       "      <td>cd_1</td>\n",
       "      <td>541211</td>\n",
       "      <td>OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978042092</td>\n",
       "      <td>THORSNES BARTOLOTTA MCGUIRE LLP</td>\n",
       "      <td>cd_3</td>\n",
       "      <td>5411</td>\n",
       "      <td>LEGAL SERVICES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979046817</td>\n",
       "      <td>KORENIC &amp; WOJDOWSKI LLP</td>\n",
       "      <td>cd_7</td>\n",
       "      <td>5412</td>\n",
       "      <td>ACCOUNTING/TAX PREP/BOOKKEEP/PAYROLL SERVICES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_key                                      dba_name council_district  \\\n",
       "0  1974000448                             ERNST & YOUNG LLP             cd_1   \n",
       "1  1974011093  HECHT SOLBERG ROBINSON GOLDBERG & BAGLEY LLP             cd_3   \n",
       "2  1978039819                                    RSM US LLP             cd_1   \n",
       "3  1978042092               THORSNES BARTOLOTTA MCGUIRE LLP             cd_3   \n",
       "4  1979046817                       KORENIC & WOJDOWSKI LLP             cd_7   \n",
       "\n",
       "  naics_code                              naics_description  naics_nchar  \n",
       "0     541211        OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS            6  \n",
       "1       5411                                 LEGAL SERVICES            4  \n",
       "2     541211        OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS            6  \n",
       "3       5411                                 LEGAL SERVICES            4  \n",
       "4       5412  ACCOUNTING/TAX PREP/BOOKKEEP/PAYROLL SERVICES            4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics</th>\n",
       "      <th>naics_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111140</td>\n",
       "      <td>Wheat Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111160</td>\n",
       "      <td>Rice Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111150</td>\n",
       "      <td>Corn Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111110</td>\n",
       "      <td>Soybean Farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111120</td>\n",
       "      <td>Oilseed (except Soybean) Farming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    naics                 naics_description\n",
       "0  111140                     Wheat Farming\n",
       "1  111160                      Rice Farming\n",
       "2  111150                      Corn Farming\n",
       "3  111110                   Soybean Farming\n",
       "4  111120  Oilseed (except Soybean) Farming"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_sd_use = [\"naics_code\", \"account_key\"]\n",
    "cols_naics_use = [\"naics\"]\n",
    "\n",
    "sd_df[cols_sd_use] = sd_df[cols_sd_use].astype(str)\n",
    "naics_df[cols_naics_use] = naics_df[cols_naics_use].astype(str)\n",
    "\n",
    "sd_df.head()\n",
    "naics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 \"Inner join\"- retain only San Diego businesses with details on their NAICS code\n",
    "\n",
    "- Use the `naics_code` column in the San Diego business data as the join key\n",
    "- Use the `naics` column in the NAICS code details data as the join key\n",
    "\n",
    "- Do an inner join of the San Diego data onto the NAICS code details using these join keys\n",
    "- After the inner join, print some examples of San Diego businesses lost in the merge\n",
    "- Use value_counts() on the `naics_nchar` column in the San Diego data to see why they might have gotten lost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 \"Left join\"- retain all sd businesses even if naics code isn't in the naics_details df\n",
    "\n",
    "- Using the same join keys as above, and treating the San Diego businesses as the left hand side data, left join the naics code details onto the San Diego businesses\n",
    "- Use the `indicator` argument within merge to create an indicator, `naics_merge_status`, to help with later merge diagnostics and examine sample of ones that didn't merge]\n",
    "- Use the `suffixes` argument within merge to add `_sd` as the left suffix, `_census` as the right suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Use group by and agg to see if there are differences in merge rates by area\n",
    "\n",
    "- Using the left-joined dataframe created in previous step, create a boolean indicator---`is_lost` if the merge indicator is equal to \"left_only\"\n",
    "- Group by `council_district` and use the shortcut of taking the mean of a True/False indicator to find the proportions in order to find the proportion lost in the merge (so in the left join, ones that failed to match to `naics_df`) by council_district\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Practice for you: add lagging 0's and see if merge rate from left join improves\n",
    "\n",
    "You noticed earlier that a big reason for non-matches is that the San Diego tax certificate NAICS codes were oftentimes not 6-digits long, while the Census ones were always 6 digits\n",
    "\n",
    "You wonder if this is an issue where 0's in some of the SD's data naics codes got cutoff (eg 540000 became 54) and if adding these lagging zeros would improve the merge rate in a left join\n",
    "\n",
    "- Using one of two approaches, pad the `naics_code` column in `sd_df` with 0's to get that column up to 6-digits: (1) str.pad in pandas (https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html); (2) for more of a challenge, write your own function that checks the # of digits in the naics code string and pads with 0's at the end up to 6 digits and use row-wise apply---`df.apply(funcname, axis = 1)`---to execute it\n",
    "- Perform the same left join as in 2.3 and see how the match rate changes\n",
    "- Create an indicator variable--`is_new_match`---for new matches under the padded NAICS code; compare the `naics_description` column from San Diego versus Census in the new dataset for a sample of these new matches and comment on whether the padding seems to be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

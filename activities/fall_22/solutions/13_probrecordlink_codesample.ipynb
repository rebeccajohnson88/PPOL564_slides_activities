{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "## a couple recordlinkage packages\n",
    "import fuzzywuzzy\n",
    "import recordlinkage\n",
    "\n",
    "## nltk for string distance\n",
    "import nltk\n",
    "\n",
    "## jarowinkler\n",
    "from pyjarowinkler import distance\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load and view the head of the two datasets\n",
    "\n",
    "Located in `public_data` in our class repo:\n",
    "\n",
    "- `sd_forfuzzy.csv`: subsample of San Diego businesses from tax certificate data; same data we used in exact match activity with NAICS codes\n",
    "- `ppploans_forfuzzy.csv`: sample of businesses in San Diego that received federal Paycheck Protection Program (PPP) loans for help weathering COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dba_name</th>\n",
       "      <th>business_owner_name</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>address_no</th>\n",
       "      <th>address_pd</th>\n",
       "      <th>address_road</th>\n",
       "      <th>address_sfx</th>\n",
       "      <th>address_city</th>\n",
       "      <th>address_zip</th>\n",
       "      <th>zip_6dig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLEINFELDER CONSTRUCTION SERVICES</td>\n",
       "      <td>KLEINFELDER CONSTRUCTION SERVICES INC</td>\n",
       "      <td>54161</td>\n",
       "      <td>550</td>\n",
       "      <td>W</td>\n",
       "      <td>C</td>\n",
       "      <td>ST</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92101-3532</td>\n",
       "      <td>92101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KLEINFELDER INC</td>\n",
       "      <td>KLEINFELDER INC</td>\n",
       "      <td>541615</td>\n",
       "      <td>770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01ST</td>\n",
       "      <td>AVE</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92101-6171</td>\n",
       "      <td>92101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PN SHUTTLE SERVICE</td>\n",
       "      <td>NICHOLAS C WATSON &amp; PAUL M BAK-SKLENER</td>\n",
       "      <td>4855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92176-1038</td>\n",
       "      <td>92176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DENTAL ARTICULATING PAPER CO</td>\n",
       "      <td>KLEIN STEVEN H</td>\n",
       "      <td>422</td>\n",
       "      <td>9285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOWDY</td>\n",
       "      <td>DR</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92126-6381</td>\n",
       "      <td>92126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLORS INTERIOR DESIGN</td>\n",
       "      <td>CHIEN-HO SUN</td>\n",
       "      <td>54141</td>\n",
       "      <td>17303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARRANZA</td>\n",
       "      <td>DR</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92127-1326</td>\n",
       "      <td>92127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dba_name                     business_owner_name  \\\n",
       "0  KLEINFELDER CONSTRUCTION SERVICES   KLEINFELDER CONSTRUCTION SERVICES INC   \n",
       "1                    KLEINFELDER INC                         KLEINFELDER INC   \n",
       "2                 PN SHUTTLE SERVICE  NICHOLAS C WATSON & PAUL M BAK-SKLENER   \n",
       "3       DENTAL ARTICULATING PAPER CO                          KLEIN STEVEN H   \n",
       "4             COLORS INTERIOR DESIGN                            CHIEN-HO SUN   \n",
       "\n",
       "   naics_code address_no address_pd address_road address_sfx address_city  \\\n",
       "0       54161        550          W            C          ST    SAN DIEGO   \n",
       "1      541615        770        NaN         01ST         AVE    SAN DIEGO   \n",
       "2        4855        NaN        NaN          NaN         NaN    SAN DIEGO   \n",
       "3         422       9285        NaN        DOWDY          DR    SAN DIEGO   \n",
       "4       54141      17303        NaN     CARRANZA          DR    SAN DIEGO   \n",
       "\n",
       "  address_zip  zip_6dig  \n",
       "0  92101-3532     92101  \n",
       "1  92101-6171     92101  \n",
       "2  92176-1038     92176  \n",
       "3  92126-6381     92126  \n",
       "4  92127-1326     92127  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(408, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BorrowerName</th>\n",
       "      <th>BorrowerAddress</th>\n",
       "      <th>BorrowerCity</th>\n",
       "      <th>BorrowerZip</th>\n",
       "      <th>FranchiseName</th>\n",
       "      <th>NAICSCode</th>\n",
       "      <th>BorrowerZip_6dig</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPSILON SYSTEMS SOLUTIONS INC</td>\n",
       "      <td>9242 LIGHTWAVE AVE Ste 100</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92123-6402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336611.0</td>\n",
       "      <td>92123</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YMCA OF SAN DIEGO COUNTY</td>\n",
       "      <td>3708 Ruffin Rd</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>92123-1812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>813410.0</td>\n",
       "      <td>92123</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CERCA TROVA RESTAURANT GROUP HOLDINGS, INC.</td>\n",
       "      <td>7676 HAZARD CENTER DR</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92108-4501</td>\n",
       "      <td>Outback Steakhouse</td>\n",
       "      <td>722511.0</td>\n",
       "      <td>92108</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RETAIL SERVICES WIS CORPORATION</td>\n",
       "      <td>9265 SKY PARK CT STE 100</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92123-4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>561499.0</td>\n",
       "      <td>92123</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE KLEINFELDER GROUP, INC.</td>\n",
       "      <td>550 West C Street</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>92101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>541330.0</td>\n",
       "      <td>92101</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  BorrowerName             BorrowerAddress  \\\n",
       "0                EPSILON SYSTEMS SOLUTIONS INC  9242 LIGHTWAVE AVE Ste 100   \n",
       "1                     YMCA OF SAN DIEGO COUNTY              3708 Ruffin Rd   \n",
       "2  CERCA TROVA RESTAURANT GROUP HOLDINGS, INC.       7676 HAZARD CENTER DR   \n",
       "3              RETAIL SERVICES WIS CORPORATION    9265 SKY PARK CT STE 100   \n",
       "4                  THE KLEINFELDER GROUP, INC.           550 West C Street   \n",
       "\n",
       "  BorrowerCity BorrowerZip       FranchiseName  NAICSCode  BorrowerZip_6dig  \\\n",
       "0    SAN DIEGO  92123-6402                 NaN   336611.0             92123   \n",
       "1    San Diego  92123-1812                 NaN   813410.0             92123   \n",
       "2    SAN DIEGO  92108-4501  Outback Steakhouse   722511.0             92108   \n",
       "3    SAN DIEGO  92123-4375                 NaN   561499.0             92123   \n",
       "4    SAN DIEGO       92101                 NaN   541330.0             92101   \n",
       "\n",
       "         Race               Ethnicity  \n",
       "0  Unanswered       Unknown/NotStated  \n",
       "1  Unanswered       Unknown/NotStated  \n",
       "2  Unanswered       Unknown/NotStated  \n",
       "3       White  Not Hispanic or Latino  \n",
       "4  Unanswered       Unknown/NotStated  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5580, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code to load the two datasets and view head\n",
    "## NOTE: if following along and you moved this notebook to another\n",
    "## directory, you'll need to change the pathname\n",
    "\n",
    "sd = pd.read_csv(\"../../../public_data/sd_forfuzzy.csv\")\n",
    "sd.head()\n",
    "sd.shape\n",
    "\n",
    "\n",
    "ppp = pd.read_csv(\"../../../public_data/ppploans_forfuzzy.csv\")\n",
    "ppp.head()\n",
    "ppp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try exact matching using sd as the left hand side\n",
    "## data and business name\n",
    "test_exact = pd.merge(sd, \n",
    "                     ppp,\n",
    "                     how = \"left\",\n",
    "                     left_on = [\"dba_name\", \"zip_6dig\"],\n",
    "                     right_on = [\"BorrowerName\",\n",
    "                                \"BorrowerZip_6dig\"],\n",
    "                     suffixes = [\"_sd\", \"_ppp\"],\n",
    "                     indicator = \"sd_match_status\")\n",
    "test_exact.sd_match_status.value_counts()\n",
    "\n",
    "## see only two real matches (duran freight duplicated \n",
    "## across non-cap and cap address)\n",
    "test_exact.loc[test_exact.sd_match_status == \"both\",\n",
    "              ['dba_name', 'BorrowerName',\n",
    "              'zip_6dig', 'BorrowerZip_6dig',\n",
    "              'BorrowerAddress']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. More manual approach to fuzzy matching\n",
    "\n",
    "In these cells, we'll review what's going on \"under the hood\" in fuzzy matching packages. We'll use an example of two PPP loan recipient businesses:\n",
    "\n",
    "- THE KLEINFELDER GROUP, INC.\n",
    "- DURAN FREIGHT CORPORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Write regex patterns to find possible matches\n",
    "\n",
    "In these cells, we:\n",
    "    \n",
    "- Define a regex pattern to characterize variations of each of the PPP business names\n",
    "- Use list comprehension and `re.match` (covered in regex lecture) to find candidate businesses in the San Diego data for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klein_patt = r\".*(\\s+)?KLEINFELDER\\s+.*\"\n",
    "klein_possible = [biz for biz in sd.dba_name\n",
    "                 if re.match(klein_patt, biz) is not None]\n",
    "klein_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duran_patt = r\".*(\\s+)?DURAN\\s+.*\"\n",
    "duran_possible = [biz for biz in sd.dba_name\n",
    "                 if re.match(duran_patt, biz) is not None]\n",
    "duran_possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Calculate string similarity in business names\n",
    "\n",
    "For Kleinfelder Group in the PPP data, we see two possible matches: Kleinfelder INC and Kleinfelder Construction Services. The first approach is, still focusing on the business name field, to calculate the string similarity between the name as spelled in the PPP loan data and the name as spelled in the San Diego tax data\n",
    "\n",
    "**General approach**: minimize the distance between the strings\n",
    "\n",
    "**Specifics**: there are many string similarity/distance metrics. Here, we'll focus on a couple:\n",
    "\n",
    "1. edit distance (aka Levensthein): finds the # of deletions, substitutions, and insertions required to transform string A into string B\n",
    "2. jaccard distance: transforms each string into a set of unique letters; calculates the \"jaccard similarity\" metric which is the intersection of string set A and string set B divided by the union of the strings; distance is 1-similarity\n",
    "3. jaro-winkler distance: broadly measures number of characters in common (jaro part of the alg.) and winkler part of the alg makes similarities at the beginning of the string count more than similarities at the end\n",
    "\n",
    "For more discussion, see:\n",
    "\n",
    "- Discussion of edit versus jaccard: https://python.gotrained.com/nltk-edit-distance-jaccard-distance/\n",
    "- Discussion of `fuzzywuzzy` package for string similarity: https://towardsdatascience.com/fuzzy-string-matching-in-python-68f240d910fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, let's process the biz name\n",
    "## and remove everything that's not (^)\n",
    "## words or spaces and also remove the \"the\"\n",
    "## at the beginning of the string\n",
    "focal_ppp_raw = \"THE KLEINFELDER GROUP, INC.\"\n",
    "focal_ppp_cleaner = re.sub(\"THE\\s\", \n",
    "                           \"\", \n",
    "                    re.sub(r\"[^\\w\\s]\", \"\", focal_ppp_raw))\n",
    "focal_ppp_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### look at a few different distance metrics\n",
    "sd['dist_focal_edit'] = [nltk.edit_distance(focal_ppp_cleaner, other_name)\n",
    "                     for other_name in sd.dba_name]\n",
    "\n",
    "sd[['dba_name', 'dist_focal_edit']].sort_values(by = 'dist_focal_edit')\n",
    "\n",
    "sd['dist_focal_jacc'] = [nltk.jaccard_distance(set(focal_ppp_cleaner), set(other_name))\n",
    "                     for other_name in sd.dba_name]\n",
    "\n",
    "sd[['dba_name', 'dist_focal_jacc']].sort_values(by = 'dist_focal_jacc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jaro is similarity score so 1 - that\n",
    "sd['dist_focal_jaro'] = [1-distance.get_jaro_distance(focal_ppp_cleaner, other_name,\n",
    "                                        winkler = True, scaling = 0.1)\n",
    "                     for other_name in sd.dba_name]\n",
    "\n",
    "sd[['dba_name', 'dist_focal_jaro']].sort_values(by = 'dist_focal_jaro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Use the zip code field to try rule out false positive matches\n",
    "\n",
    "\"Blocking\" on 6-digit zip code, or requiring an exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the zip- using iloc since we just want it as a string\n",
    "## rather than series\n",
    "focal_ppp_zip = ppp.loc[ppp.BorrowerName == \n",
    "                \"THE KLEINFELDER GROUP, INC.\",\n",
    "                [\"BorrowerName\",\n",
    "                 \"BorrowerAddress\",\n",
    "                 \"BorrowerZip_6dig\", \"NAICSCode\"]].copy()\n",
    "focal_ppp_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create true false if same as focal biz\n",
    "sd['is_match_zip'] = np.where(sd.zip_6dig == \n",
    "                    focal_ppp_zip.BorrowerZip_6dig.iloc[0],\n",
    "                    True, False)\n",
    "\n",
    "sd.loc[(sd.is_match_zip) &\n",
    "      (sd.dba_name.isin(klein_possible)),\n",
    "      ['dba_name'] + [col for col in sd.columns if \"address\" in col] + \n",
    "      [\"zip_6dig\", \"naics_code\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Construct a match score summarizing these two fields (zip code and name similarity)\n",
    "\n",
    "Record linkage methods have different ways for aggregating across fields\n",
    "\n",
    "Here, we're going with a simple one of:\n",
    "\n",
    "- Need to match the zip code of the focal Kleinfelder group directly\n",
    "- Within those, find the average of the jarowinkler and jaccard string distance measures (we're excluding edit distance from that avg since on diff scale)\n",
    "\n",
    "Whichever has the lowest average of two we consider the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get string distance column names\n",
    "string_dist_fields = [col for col in sd.columns if \"dist_\" in col and \n",
    "                     \"edit\" not in col]\n",
    "\n",
    "\n",
    "## take the row mean (axis = 1) across those columns\n",
    "mean_distances = sd[string_dist_fields].mean(axis = 1)\n",
    "\n",
    "## assign that as a new column\n",
    "sd['mean_string_dist'] = mean_distances\n",
    "\n",
    "## sort from highest to lowest string\n",
    "## distance among matches\n",
    "sd.loc[sd.is_match_zip].sort_values(by = \n",
    "                    \"mean_string_dist\").head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview of activity step 1: clean addresses in each of the datasets\n",
    "\n",
    "Previous example shows us address can help adjudicate between matches.\n",
    "\n",
    "For the activity: \n",
    "    \n",
    "- Paste together the address_no, address_pd, address_road, address_sfx fields in the SD active biz to create a field similar to `BorrowerAddress` in the PPP loan data \n",
    "- When doing so, make sure to pay attention to the following issues that might cause failures to clean / match:\n",
    "    - NaN in inputs to the address fields in the San Diego data; if you paste the string literally, these will show up as NaN; better to convert to \"\" or whitespace\n",
    "    - Capitalization: make sure to standardize the capitalization so that the addresses in both datasets are either all lowercase or all uppercase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. That was a lot of steps. How can we use a package to automate a bit?\n",
    "\n",
    "Google \"fuzzy matching\" or \"probablistic record linkage\" packages in python\n",
    "\n",
    "Here, we'll focus on \n",
    "\n",
    "- recordlinkage. Documentation: https://recordlinkage.readthedocs.io/en/latest/notebooks/link_two_dataframes.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Clean potential join fields (here: focus on BorrowerName in PPP; dba_name in SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean name similarly to how we did before\n",
    "ppp['bizname_4match'] = [re.sub(r\"[^\\w\\s]\", \"\", one_n) \n",
    "                         for one_n in ppp.BorrowerName]\n",
    "ppp.loc[ppp.bizname_4match != ppp.BorrowerName,\n",
    "       ['BorrowerName', 'bizname_4match']].head()\n",
    "\n",
    "sd['bizname_4match'] = [re.sub(r\"[^\\w\\s]\", \"\", one_n) \n",
    "                        for one_n in sd.dba_name]\n",
    "sd.loc[sd.bizname_4match != sd.dba_name,\n",
    "       ['dba_name', 'bizname_4match']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: for ease of use, standardize colnames for the fields we'll use\n",
    "\n",
    "In this practice exercise, we'll use:\n",
    "\n",
    "- Fuzzy match on business name\n",
    "- Exact match on 6-digit zip code\n",
    "\n",
    "We only need to standardize the name of the exact match field, but are here just standardizing all for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define rename dictionary for sd_biz and rename saving to new (just for convenience to not reload if we want to\n",
    "## change earlier step)\n",
    "newcols_sd = {'zip_6dig': 'zip_4match'}\n",
    "sd = sd.rename(columns = newcols_sd, inplace = False)\n",
    "\n",
    "## same for ppp data\n",
    "newcols_ppp = {'BorrowerZip_6dig': 'zip_4match'}\n",
    "ppp = ppp.rename(columns = newcols_ppp, inplace = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: initialize the match object and tell it if anything to \"block on\" or exact match\n",
    "\n",
    "Here, we're blocking on 6-digit zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize indexer\n",
    "my_recordmatcher = recordlinkage.Index()\n",
    "print(type(my_recordmatcher))\n",
    "\n",
    "## tell it what to block on (skip if not blocking on anything)\n",
    "my_recordmatcher.block(\"zip_4match\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4: create candidate links based on that blocking variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then, feed the record matcher the two datasets (must have that blocking variable)\n",
    "## this will create candidate_links that are exact matches on those\n",
    "candidate_links_zip = my_recordmatcher.index(sd, ppp)\n",
    "candidate_links_zip\n",
    "\n",
    "print(type(candidate_links_zip))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see that it's a list of tuples and first element in tuple is index\n",
    "## of first df we feed it; second is index in second df we feed it\n",
    "\n",
    "## print example of links\n",
    "sd.loc[sd.index == 242,\n",
    "        [col for col in sd.columns if \"4match\" in col]]\n",
    "ppp.loc[ppp.index.isin([1081, 2351]),\n",
    "        [col for col in ppp.columns if \"4match\" in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5- initialize Compare class and define fuzzy fields and threshold for each\n",
    "\n",
    "Note in documentation about diff string compare methods:\n",
    "\n",
    "This class is used to compare string values. The implemented algorithms are: ‘jaro’,’jarowinkler’, ‘levenshtein’, ‘damerau_levenshtein’, ‘qgram’ or ‘cosine’. In case of agreement, the similarity is 1 and in case of complete disagreement it is 0. The Python Record Linkage Toolkit uses the jellyfish package for the Jaro, Jaro-Winkler, Levenshtein and Damerau- Levenshtein algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = recordlinkage.Compare()\n",
    "print(type(compare))\n",
    "\n",
    "thres_bizname = 0.65\n",
    "compare.string('bizname_4match', 'bizname_4match', \n",
    "               method='jaro', threshold=thres_bizname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6- using the compare Class and the candidate links, compute comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use compare class to compute\n",
    "## feed it (1) candidate links based on zip code blocking\n",
    "## and string comparison, (2) raw datasets (order matters)\n",
    "compare_vectors = compare.compute(candidate_links_zip, sd, ppp)\n",
    "compare_vectors\n",
    "print(type(compare_vectors))\n",
    "\n",
    "## convert to a dataframe- the leftmost index is sd \n",
    "## since that's the first/left data; the right index is\n",
    "## ppp since that's the second/right data; see that \n",
    "## most are non-matches\n",
    "compare_vectors_df = pd.DataFrame(compare_vectors.reset_index())\n",
    "compare_vectors_df.columns = [\"index_sd\", \"index_ppp\", \"name_match\"]\n",
    "compare_vectors_df.sample(n = 5)\n",
    "compare_vectors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## get the ppp row index of the Kleinfelder group business\n",
    "index_klein = ppp.index[ppp.bizname_4match == \"THE KLEINFELDER GROUP INC\"]\n",
    "\n",
    "## using the dataframe version of compare, look for\n",
    "## sd data indices of matches\n",
    "poss_klein = compare_vectors_df[\\\n",
    "                compare_vectors_df.index_ppp.isin(index_klein) &\n",
    "                compare_vectors_df.name_match == 1]\n",
    "poss_klein\n",
    "\n",
    "## print results\n",
    "sd.loc[sd.index.isin(poss_klein.index_sd),\n",
    "      ['bizname_4match', 'zip_4match']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. decide what counts as a true match\n",
    "\n",
    "Three general approaches:\n",
    "\n",
    "- Threshold based: look at the raw scores and determine what scores are above a threshold\n",
    "- Unsupervised: something that clusters the pairs into \"likely match\" or \"likely not match\" but where we're not feeding it \"labels\" corresponding to true matches\n",
    "- Supervised: we have some gold-standard label dataset that has an indicator for whether records are true matches; we train a model on those true matches and generalize to new cases\n",
    "\n",
    "See here for many classifiers: https://recordlinkage.readthedocs.io/en/latest/ref-classifiers.html\n",
    "\n",
    "Here, we're using unsupervised and k-means clustering algorithm\n",
    "\n",
    "Other option is an EM-based classifier initialized as follows, but not enough data here to fit:\n",
    "ecm = recordlinkage.ECMClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize classifier\n",
    "kmeans = recordlinkage.KMeansClassifier()\n",
    "kmeans_results = kmeans.fit_predict(compare_vectors)\n",
    "print(type(kmeans_results))\n",
    "kmeans_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8:  extract pairs using indices and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## since sd was our left hand side data, they're \n",
    "## the first index in the tuple- extract\n",
    "indices_sd = [x[0] for x in kmeans_results]\n",
    "\n",
    "## since ppp loans were our right hand side data, they're\n",
    "## the second index in the tuple - extract\n",
    "indices_ppp = [x[1] for x in kmeans_results]\n",
    "\n",
    "## create dataframe\n",
    "df_matchpairs = pd.DataFrame({'sd_indices': indices_sd,\n",
    "                'ppp_indices': indices_ppp})\n",
    "\n",
    "df_matchpairs\n",
    "\n",
    "## add indices as col to orig data\n",
    "sd['index_4merge'] = sd.index\n",
    "ppp['index_4merge'] = ppp.index\n",
    "\n",
    "## then, join matches\n",
    "\n",
    "### first, i'm joining the sd info\n",
    "df_matchpairs_wsd = pd.merge(df_matchpairs,\n",
    "                            sd,\n",
    "                            how = \"left\",\n",
    "                            left_on = \"sd_indices\",\n",
    "                            right_on = \"index_4merge\")\n",
    "\n",
    "## then, i'm joining the ppp info and adding a suffix to distinguish the vars\n",
    "df_matchpairs_wboth = pd.merge(df_matchpairs_wsd,\n",
    "                              ppp,\n",
    "                              how = \"left\",\n",
    "                              left_on = \"ppp_indices\",\n",
    "                              right_on = \"index_4merge\",\n",
    "                              suffixes= [\"_sd\", \"_ppp\"])\n",
    "\n",
    "df_matchpairs_wboth[['bizname_4match_sd', 'bizname_4match_ppp',\n",
    "                     'zip_4match_sd', 'zip_4match_ppp',\n",
    "                     'BorrowerAddress'] + \n",
    "                   [col for col in sd.columns if \n",
    "                   \"address\" in col]].head()\n",
    "\n",
    "## see some true and false positives; would want to use business address"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
